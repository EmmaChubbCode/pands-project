{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook investigates the famous Fisher Iris dataset (Fisher, R. (1936). Iris [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56C76.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import necessary libraries for importing data and whatever analysis follows\n",
    "# will put these in a requirements file later\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder as le\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Acquiring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step involves acquiring the data. \n",
    "Data has been downloaded from https://archive.ics.uci.edu/dataset/53/iris which includes the option to import data using python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ucimlrepo is a package for importing datasets from the the UC Irvine Machine Learning Repository.\n",
    "# See: https://github.com/uci-ml-repo/ucimlrepo     \n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the datas. the ID specifies whic of the UCI datasets you want.\n",
    "iris = fetch_ucirepo(id=53) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that is fetched also contains metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata contains details of the dataset including its main characterisics, shape, info on missing data, and relevant links (e.g. where to find raw data) \n",
    "# the meta data also contains detailed additional information including text descriptions of variables, funding sources, and the purpose of the data, \n",
    "print(iris.metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take the data and save it to a variable called iris\n",
    "iris = iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Initial exploration of data package structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print iris to see what it contains\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, when you load iris data it returns as a dictionary-like object which contains a list of features, a list of classes, and each instance of the dataset.\n",
    "What do each of these elements represent?\n",
    "- Each class represents a different species of iris\n",
    "- Each feature represents a different measured aspect of the flowers\n",
    "- Each instance represents a specific flower and the measurements of its features in centimeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at each of these below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the features of the data. you can see the columns represent sepal length, sepal width, petal length, and petal width.\n",
    "print(iris.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the targets are labels for the data. in this case, they are the species of iris flower (setosa, versicolor, virginica).\n",
    "print(iris.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Explore and summarise the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to have both the targets and features in one dataframe to make my analysis and code easier. \n",
    "# the code in x suggests putting the targets and features into x and y variables.\n",
    "# data (as pandas dataframes) \n",
    "X = iris.features \n",
    "y = iris.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i then used these two variables to create a new dataframe called iris_df.\n",
    "# we'll use the pandas function concat to do this. we'll specify we're joining on aixs=1, which means we're joining on the columns. \n",
    "# see: https://pandas.pydata.org/docs/user_guide/merging.html#joining-logic-of-the-resulting-axis \n",
    "iris_df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore our new dataframe. we'll start looking at the top and bottom 5 rows to get a sense of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return top 5 rows\n",
    "# see: https://www.w3schools.com/python/pandas/ref_df_head.asp#:~:text=The%20head()%20method%20returns,a%20number%20is%20not%20specified.&text=Note%3A%20The%20column%20names%20will,addition%20to%20the%20specified%20rows.\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return bottom 5 rows.\n",
    "# https://www.w3schools.com/python/pandas/ref_df_tail.asp#:~:text=The%20tail()%20method%20returns,a%20number%20is%20not%20specified.\n",
    "iris_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check the types of data in iris. we can see that each column is a float64 type, except for the target/class column.\n",
    "iris_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move on to summarizing the basic descriptive aspects of the dataset, which will tell us about the flowers themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data set. This will show basic descriptive statistics for each column in the dataframe.\n",
    "# This includes the count, mean, standard deviation, min, max, and 25th, 50th, and 75th percentiles.\n",
    "# see: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html \n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check for nulls by combining the ifnull function with the sum function\n",
    "# see: https://www.w3schools.com/python/pandas/ref_df_isnull.asp \n",
    "# and https://www.w3schools.com/python/pandas/ref_df_sum.asp\n",
    "print(iris_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe has down us the mean, median and quartiles for each column. Let's look other measures of distirbution for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of sepal length: 0.3149109566369728\n",
      "Skewness of sepal width: 0.3340526621720866\n",
      "Skewness of petal length: -0.27446425247378287\n",
      "Skewness of petal width: -0.10499656214412734\n"
     ]
    }
   ],
   "source": [
    "# the skew function will show us the skewness of the data. the skewness of a measure of how distributed the data is around the mean. \n",
    "# see: https://www.datacamp.com/tutorial/understanding-skewness-and-kurtosis \n",
    "# i want it for each column so im going to use for loop to save time. see: https://statisticsglobe.com/iterate-over-columns-pandas-dataframe-python \n",
    "\n",
    "# for each column in iris df, calculate the skewness and then print it out.  \n",
    "for column in iris_df:\n",
    "   if column != 'class': # first check if the column is not the class column. that has strings so won't work - learned this from earlier error. \n",
    "    skew = iris_df[column].skew()\n",
    "    print (f\"Skewness of {column}: {skew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kurtosis of sepal length: -0.5520640413156395\n",
      "Kurtosis of sepal width: 0.2907810623654279\n",
      "Kurtosis of petal length: -1.4019208006454036\n",
      "Kurtosis of petal width: -1.3397541711393433\n"
     ]
    }
   ],
   "source": [
    "# Similarly, we can check the data for kurtosis. According to data camp, \"kurtosis focuses more on the height. It tells us how peaked or flat our normal (or normal-like) distribution is. \n",
    "# see https://www.datacamp.com/tutorial/understanding-skewness-and-kurtosis\n",
    "# for each column in iris df, calculate the skewness and then print it out.  \n",
    "for column in iris_df:\n",
    "   if column != 'class': # first check if the column is not the class column. that has strings so won't work - learned this from earlier error. \n",
    "    kurtosis = iris_df[column].kurtosis()\n",
    "    print (f\"Kurtosis of {column}: {kurtosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the analysis above that the mean and median are largely similar. Similarly, both our skewness and kurtosis are within normal range. These findingins indiate our data is fairly normally distributed and not impacted by many outliers (see: https://www.smartpls.com/documentation/functionalities/excess-kurtosis-and-skewness)\n",
    "\n",
    "The mean sepal length across the dataset is apprx. 5.6cm. The mean sepal width is approx. 3.1cm. While the means for petal length and width are 3.8cm and 1.2cm, resectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The class column is a string variable and therefore we cannot calculate mean, median, skewness, or kurtosis as we did above. However, we can count the occurence of each value.\n",
    "# the value_counts function will return a series containing counts of unique values. \n",
    "# see: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html \n",
    "iris_df['class'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
